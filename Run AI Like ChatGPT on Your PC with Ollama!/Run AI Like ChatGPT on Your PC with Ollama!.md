# Set Up and Run Your Own AI with Ollama

Welcome to Logan's Logical Lab! Follow these steps to download, install, and run your very own AI using Ollama. This guide is perfect for running AI on your PC, spare computer, mini server, or even a Raspberry Pi.

---

**Associated Video:** [Run AI Like ChatGPT on Your PC with Ollama!](https://youtu.be/mZJt-5zyYXk)

## Step 1: Overview

- **Purpose:** Run a local AI model instead of relying on remote data centers.
- **Benefits:**  
  - Lower cost hardware setup  
  - Your data stays on your device  
  - Independence from big tech services  
- **Requirements:**  
  - Minimum: 8 GB RAM (more is better)  
  - Supported OS: Windows 10+, macOS 11 (Big Sur)+, Linux  

---

## Step 2: Download Ollama

1. **Visit the Website:**  
   - Open your web browser and navigate to [Ollama's Website](https://www.ollama.com) 

2. **Select Your Platform:**  
   - Find the download section and choose the installer for your operating system:
     - **Windows:** Windows 10 or later
     - **macOS:** macOS 11 (Big Sur) or later
     - **Linux:** (Any supported Linux distribution)

3. **Review Software Requirements:**  
   - Check the listed software requirements to ensure your system is compatible.

---

## Step 3: Install Ollama

1. **Run the Installer:**  
   - Once the download is complete, open the installer and follow the on-screen instructions.

2. **Verify Installation:**  
   - Open your terminal (Command Prompt on Windows, Terminal on Linux/macOS) and run:
     ```bash
     ollama --version
     ```
   - You should see version information confirming that Ollama is installed correctly.

---

## Step 4: Launch Ollama and Explore Commands

1. **Open Your Terminal:**  
   - Launch your terminal or command prompt.

2. **Display Available Commands:**  
   - Type the following to see a list of commands:
     ```bash
     ollama
     ```
   - You should see options like `run`, `show`, `create`, and `serve`.

3. **Start the AI Server:**  
   - To launch the service, enter:
     ```bash
     ollama serve
     ```
   - **Note:** If you receive an error stating it’s already running, make sure you’re not duplicating the command.

---

## Step 5: Install and Run an AI Model

1. **Select Your Model:**  
   - On the Ollama website, navigate to the **Models** section.  
   - Choose a model based on your hardware capabilities. For example:
     - **Deep Seek R1 (7B parameters)** – A good AI for decent to good hardware.
     - **llama 3.2 (3B parameters)** - Good for lower end software like a Raspberry Pi.

2. **Copy the Installation Command:**  
   - Click on your chosen model and copy the provided command from the web portal.

3. **Execute the Command in Terminal:**  
   - Paste the command into your terminal. (Note: On Windows, right-click to paste if Ctrl+V doesn’t work.)
   - Press **Enter** to start the installation.
   - Installation times may vary from about 1–2 minutes for smaller models up to 30 minutes for larger ones.

---

## Step 6: Interact with Your AI

1. **Send a Test Query:**  
   - Once the model is running, try typing a simple query:
     ```bash
     "What is AI?"
     ```
   - Watch for the loading animation and response.

2. **Access Help for Commands:**  
   - To see a list of available commands while interacting with the AI, type:
     ```bash
     /?
     ```
   - This will provide guidance on how to operate your AI.

---

## Step 7: Managing Your AI Sessions

1. **Closing an AI Session:**  
   - To shut down the current AI chat and free up resources, use the shutdown command. In this guide, we’ll refer to it as:
     ```bash
     /bye
     ```
   - This safely closes the session.

2. **Restarting or Installing Additional Models:**  
   - You can install and run more models using the same process. Keep in mind:
     - Do not run multiple models simultaneously on a single device.
     - Always shut down your current session before starting a new one.

---

## Step 8: Optional Enhancements

1. **Integrate Open Web UI:**  
   - For additional functionality (e.g., real-time data access, enhanced chat features), consider using [Open Web UI]([https://github.com/openwebui](https://github.com/open-webui/open-webui)).
   - **Requirements:** Docker must be installed to run Open Web UI.

2. **Follow Additional Guides:**  
   - Check the repository for further instructions or visit the linked GitHub pages for more detailed documentation.

---

## Final Notes

- **Resource Management:** AI models can use significant processing power and memory. Always shut down unused sessions.
- **Hardware Considerations:** While this setup works on systems with 8GB RAM, performance improves with more resources.
- **Data Privacy:** Running your AI locally ensures that your queries and data are kept on your device.

Congratulations! You now have your own AI running locally. Enjoy exploring and expanding your projects with this setup.

If you encounter any issues or have questions, please open an issue in this repository or refer to Logan’s Logical Lab’s video description for more resources.

**Happy coding,**  
**Logan**  
